/home/alberto/lab/.venv/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
You seem to be using sentence-transformers/multi-qa-mpnet-base-dot-v1 model with the cosine function instead of the recommended dot_product. This can be set when initializing the DocumentStore
Converting files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 13.87it/s]
Preprocessing: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 91.46docs/s]
Batches:   0%|                                                                                                                                                                                                  | 0/1 [00:00<?, ?it/s]
Retriever:  <haystack.nodes.retriever.dense.EmbeddingRetriever object at 0x7fa12b28fd10>
Processing files:
Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.90s/it]
Document id d481e014691313fa49897ad082916399 is not in uuid format. Such ids will be replaced by uuids, in this case 1d43e2e3-6114-32c7-d82f-8598abce23f6.
  0%|                                                                                                                                                                                                           | 0/5 [00:00<?, ?it/s]/home/alberto/lab/.venv/lib/python3.11/site-packages/weaviate/warnings.py:80: DeprecationWarning: Dep002: You are batching manually. This means you are NOT using the client's built-in
            multi-threading. Setting `batch_size` in `client.batch.configure()`  to an int value will enabled automatic
            batching. See:
            https://weaviate.io/developers/weaviate/current/restful-api-references/batch.html#example-request-1
  warnings.warn(
Finished processing files
#####################
Embeddings Completed.
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 44.94it/s]
Retriever:  <haystack.nodes.retriever.dense.EmbeddingRetriever object at 0x7fa12811c150>
Prompt:  <haystack.nodes.prompt.prompt_node.PromptNode object at 0x7fa12b2c21d0>
Ranker:  <haystack.nodes.ranker.cohere.CohereRanker object at 0x7fa12807b7d0>
You seem to be using sentence-transformers/multi-qa-mpnet-base-dot-v1 model with the cosine function instead of the recommended dot_product. This can be set when initializing the DocumentStore
Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.75it/s]
Answer:  {'answers': [<Answer {'answer': 'The documents do not provide information on how Revolut would be impacted by AIG going bankrupt.', 'type': 'generative', 'score': None, 'context': None, 'offsets_in_document': None, 'offsets_in_context': None, 'document_ids': ['85efa80d-6fb7-03f3-e47f-e09541b7ffac', '6cd2e7cf-4ad3-032c-a3c2-da8d53861889', 'e0ab4244-e71f-113c-cfe1-94fb0fd52e52', '1d43e2e3-6114-32c7-d82f-8598abce23f6', '5ac6e8ee-98b1-7f4e-ea4f-4cf184155fea'], 'meta': {'prompt': 'Given the provided Documents, answer the Query.\n\n                                                Query: How would Revolut be impacted by AIG going bankrupt?\n\n                                                Documents: 4.b.i Windowing\nTo obtain a risk prediction for a given driver, first establish when their most recent trip occurred. Retrieve a historic dataset of their behaviour looking back from this most recent trip. This\nhistoric dataset is the driver window.\nWe propose that the window size is 30 days.\nNote that we will probably need to impose a minimum distance on this window, such as 250km of driving, to ensure some stability in the score. We can use this minimum distance as\nthe requirement for giving drivers their first driver score, which means we do not have to wait for the full 30 days before a driver or fleet can get their score.\n4.b.ii Normalisation\nWe normalise the output of the risk models such that, for each driver setting group, the expected output of the model across all drivers, weighted by their mileage, is 1. This gives us a\nconcept of relative risk for our risk models.\n4.b.iii Risk Prediction Aggregation\nRisk predictions are made at the driver setting level. That is, for each driver, we retrieve their window of driving behaviour and split it up into the setting groups. For each setting, we\naggregate the data and make a risk prediction (using the risk models) on this aggregation. Then for each driver, we aggregate up the setting-level risk predictions using a simple average,\nweighted by mileage observed in each setting.\nA pipeline (expanded to include the scoring step) of this process is illustrated below.\n4.c Scoring\nThe purpose of scoring is to convert a relative risk prediction from being an unbounded, real-valued number to an integer in a fixed range familiar to our users. Ratings from 1-100 are\ncommonplace in everyday life, so we use this as our target range.\nWe propose to provide scores at two levels only:\n1. Driver Score: This represents our current prediction about the future risk of a driver\n2. Fleet Score: This represents our current prediction about the future risk of a fleet\nIt may be preferable to use a window size based on mileage rather than time, or has some more complicated logic determining what information is included. This is not expected\nto change the majority of risk predictions but is reserved as a topic for exploration by the Data Science team in future.\nRisk models are to output a prediction which is expressed relative to the expected value for the given driver setting.\x0c4.c.i Driver Score\nDriver score is computed for each driver at a regular interval, such as daily. Every day we refresh the driver’s data window, make a new risk prediction (if necessary) and then map that\nprediction to a score using a mapping of risk → score.\nThe risk → score mapping can be updated but is expected to be slow changing.\n The proposed mapping is constructed from a large dataset of driver scores (historic data across all fleets has been used for the first mapping) as follows:\nThe lowest percentile of observed risk corresponds to a score of 100\nThe highest percentile of observed risk corresponds to a score of 1\nDivide the range between the 1st and 99th percentile of risk into 98 equal-width bins\nThis process yields a binned lookup table mapping from risk to score.\n4.c.ii Fleet Score\nWe define fleet score as a representation of a prediction about the future risk of the fleet given historic behaviour. It is important that fleet score is related to driver score in as direct and\nintuitive way as possible, so that it is easy for customers to understand, notably without referencing the unbounded risk prediction underlying the score. This last restriction protects us\nfrom the fleet score becoming opaque and ensures that driver scores and fleet score are aligned.\nTo make a prediction about the future risk of the fleet, we need to consider two aspects\n1. The risk of the individual drivers who comprise the fleet (this is represented by driver score)\n2. The expected distribution of the fleet’s future mileage amongst its drivers\nThis second point is important. It is not sufficient to just take the fleet’s average driver score and call that the fleet score. What if the best drivers drive twice as much as the worst ones?\nSo, we make a prediction about the future distribution of mileage amongst the drivers and use this as a weight in the average: Fleet score is therefore average driver score, weighted by\ndriver mileage.\nWe will stop referring to Trip Score entirely. This is because trips on their own do not contain enough information (in our current representation of our data input) to give stable risk\npredictions.\nLet fleet_score_{i,t} be the fleet score for fleet i at time t .\nLet driver_score_{i, j, t} be the driver score for driver j in fleet i at time t\x0cImplicit in this definition is that we are taking our prediction of the future mileage distribution of the fleet from its recent mileage mix. If a given driver drove 10% of the fleet’s miles in the\npast 30 days, then we expect them to continue to make a similar contribution, so their score is weighted in the aggregation by 10%. This is a naive way of making the mileage distribution\nprediction but it is as simple and intuitive.\n4.d Pricing\nThe proposal requires a fixed score → rating map for each fleet. This is so that a fleet can know what discounts or loadings are applicable for a given score before they start.\nWe propose that the score → rating map should be fixed at quote time. It may be universal or may depend on some fleet attributes that are available at time of quote, such as the\nmajority setting we expect to observe the drivers in.\n 4.d.i Determining Rating Multipliers from Score\nFor fitting the score → rating mapping for a given setting, we propose to fit a curve which is parametrised to ensure a net-zero rating across the portfolio (accounting for variations in\ndriver exposure). An example is shown below.\nLet window_size be the size of our scoring window in days (e.g. 30)\nLet mileage_{i, j, t, t-window_size} be the distance driven by driver j in fleet i between time t-window_size and t .\nThen\nfleet_score_{i, t} = wavg(driver_score_{i, j, t}, w=mileage_{i, j, t, t-window_size})\x0cMore details on parametrisation of this curve are discussed in this notebook.\n4.d.ii Alternative Pricing Tables\nGiven the proposed scoring structure, it is possible to determine a variety of pricing schemes which can fit different products. The example above is produced by the two constraints:\nMultiplicative rating is bounded between ±20%\nPortfolio effect of dynamic pricing (assuming constant behaviour) is 0\nSome alternative constraint sets which we may wish to consider (to facilitate other products) are:\nDiscount only\nMultiplicative rating is bounded between 0 and -10%\nPortfolio effect of dynamic pricing (assuming constant behaviour) is 0\nNeutral zone\nMultiplicative rating is bounded between ±20%\nScores within ±5 points of the neutral score should have no adjustment\nPortfolio effect of dynamic pricing (assuming constant behaviour) is 0\nTo fit a price → rating curve for any of these constraints, one has to simply take the historic scores and base premiums and find the parameters which satisfy them. The historic score and\nbase premium dataset\n5. Appendices\nAppendix A. Algorithms\nAppendix B: Pilot\nAppendix C: Assets\nAppendix D: RiskOS Integration\nAppendix E: User Experience Impact\nAppendix F: Onboarding Impact\nAppendix G: BenScoPe vs. Status Quo Head-to-Head\nAppendix H: Scoring and Pricing Customer Impact Analysis\nBenScoPe: How is My Premium Calculated? (PHYD)\nBenScoPe: How is My Premium Calculated? (Annual Plus) Absolute Driver Scoring (BenScoPe)\nThis Confluence page documents a proposal known as BenScoPe, which seeks to reform our benchmarking, scoring and pricing that underpins our two current Rideshur products.\nWe describe a scoring structure which can be used for delivering driver and fleet risk scores which are comparable and transferable between contexts, and which do not require the\nmaintenance of a benchmark for any given fleet.\nThe changes described here have implications for how our users will interact with the products based upon this new scoring system. These implications are out of scope for the proposal,\nbut are discussed to some degree in the appendix pages.\nContents\n1. Motivation\n2. Scope\na. Problem Statement\nb. Proposal Summary\n3. Benefits and Risks\n4. Proposal\na. Risk/Score/Price structure, incl. base model (UW)\nb. Risk modelling (incl. setting groups)\ni. Windowing\nii. Normalisation\niii. Risk Prediction Aggregation\nc. Scoring\ni. Driver Score\nii. Fleet Score\nd. Pricing\ni. Determining rating multipliers from score\nii. Alternative Pricing Tables\n5. Appendices\na. Algorithms\nb. Pilot\nc. Assets\nd. RiskOS Integration\ne. User Experience Impact\nf. Onboarding Impact\ng. BenScoPe vs. Status Quo Head-to-Head\n1. Motivation\nOur current scoring system is not delivering for customers or for Humn. For customers, the score is not providing a good enough risk measurement or a fair pricing response. For Humn,\nthe operational costs around onboarding are unsustainable and also impact our customers.\nAn enumeration of the main issues follows.\n1. Our scores are not absolute, only relative.\na. Most fleet scores hover uninspiringly around 50\nb. We can’t compare fleets to each other\nc. We can’t compare drivers from different fleets\n2. Our benchmarking process is flawed and slow\na. It delays onboarding\nb. The behaviour we observe during benchmarking may not be representative\nc. It creates a lot of day-to-day operational work, especially for the Data Science team, who make the benchmarking measurement\n3. Our risk modelling is complex, retrospective and inefficient\na. Making risk predictions at the trip level is volatile, and mitigation of this has introduced complexity\nb. Interventions can only be made at the driver level, so the focus on single trips is an error\nc. There is no need to make online predictions in order to do online pricing\n2. Scope\nThe Rideshur dynamic scoring and pricing system is the scope of this proposal.\n2.a Problem Statement\nThe system we are considering changing here aims to meet two goals\x0c1. Accurately measure risk\n2. Help customers reduce risk\n3. Collect the right amount of money to hit a given loss ratio target\nThe problem statement is therefore:\n2.b Proposal Summary\n1. No more benchmarking\n2. Risk modelling and scores made at driver level, published daily\n3. Fleet score is the average of driver scores, weighted by mileage, published daily\n4. Scores are absolute and do not depend on fleet\n5. Use a score → rating map to transform a score into a discount/loading. This can be universal or fleet specific\n6.  Use setting groups to normalise risk model outputs across different settings such as driving in vans vs driving in cars\n3. Benefits and Risks\nThe proposal aims to deliver the following benefits\nWe have identified the following risks\n4. Proposal\n4.a Base Model and Dynamic Model\nWe do not propose to change the relationship between the base model (owned by Underwriting) and the dynamic model (owned by Data Science).\nBase model provides a base price for a given fleet\nDynamic model provides a multiplicative adjustment to the base price, within the bounds of ±20%\n4.b Risk modelling\nThere are two main changes proposed here. The first is to use a window of past driver behaviour to make a risk estimate about the driver’s future behaviour. This is a deviation from our\ncurrent method of making risk estimates retrospectively at the trip level. The volatility of making retrospective estimates of risk at trip-level is illustrated here, which plots the trip scores for\na single driver over a week-long period.\nThe second change is to introduce a normalisation layer to the output of our models so that the risk estimate is given in relation to the average risk estimated over historic data.\nGiven some telematics data for a set of customers, provide:\nA score which accurately represents the risk in a way understandable and actionable for customers\nA corresponding pricing adjustment which is fair, cost-neutral and promotes improvements in behaviour with respect to risk.\nRemove the uncertainty and operational cost of benchmarking\nScores become more interpretable and have meaning in multiple contexts\nTrips no longer need to be scored individually, so we have the option to decrease load on our scoring pipeline by using batch computations instead\nA flexible framework for converting scores into prices that can accommodate more complexity as our datasets grow\nWe may collect less than the quoted premium for fleets who are less risky. This is because the system will respond more directly to behavioural change\nThere is no guarantee that a fleet will start their policy with a neutral score or rating (as is currently the case). This has the potential for a bad user experience in some cases so\nwe must try and handle this issue\nWe will no longer calculate risk estimates at the trip level and instead focus on making driver-level risk predictions about the future.\x0c4.b.i Driver Settings\nWe introduce the concept of driver settings, which are arbitrary groupings allowing us to control for different contexts in which the risk models may respond differently. For example, two\nsettings in which we might observe a driver are van and car . We propose to handle the behaviour in each setting separately, aggregating it up to the driver level after a normalisation\nstep.\nNote that driver settings can be used for more complex groupings in future if we wish, controlling for aspects other than vehicle type, such as business type.\n\n                                                Answer: \n                                            '}}>], 'invocation_context': {'query': 'How would Revolut be impacted by AIG going bankrupt?', 'documents': [<Document: {'content': '4.b.i Windowing\nTo obtain a risk prediction for a given driver, first establish when their most recent trip occurred. Retrieve a historic dataset of their behaviour looking back from this most recent trip. This\nhistoric dataset is the driver window.\nWe propose that the window size is 30 days.\nNote that we will probably need to impose a minimum distance on this window, such as 250km of driving, to ensure some stability in the score. We can use this minimum distance as\nthe requirement for giving drivers their first driver score, which means we do not have to wait for the full 30 days before a driver or fleet can get their score.\n4.b.ii Normalisation\nWe normalise the output of the risk models such that, for each driver setting group, the expected output of the model across all drivers, weighted by their mileage, is 1. This gives us a\nconcept of relative risk for our risk models.\n4.b.iii Risk Prediction Aggregation\nRisk predictions are made at the driver setting level. That is, for each driver, we retrieve their window of driving behaviour and split it up into the setting groups. For each setting, we\naggregate the data and make a risk prediction (using the risk models) on this aggregation. Then for each driver, we aggregate up the setting-level risk predictions using a simple average,\nweighted by mileage observed in each setting.\nA pipeline (expanded to include the scoring step) of this process is illustrated below.\n4.c Scoring\nThe purpose of scoring is to convert a relative risk prediction from being an unbounded, real-valued number to an integer in a fixed range familiar to our users. Ratings from 1-100 are\ncommonplace in everyday life, so we use this as our target range.\nWe propose to provide scores at two levels only:\n1. Driver Score: This represents our current prediction about the future risk of a driver\n2. Fleet Score: This represents our current prediction about the future risk of a fleet\nIt may be preferable to use a window size based on mileage rather than time, or has some more complicated logic determining what information is included. This is not expected\nto change the majority of risk predictions but is reserved as a topic for exploration by the Data Science team in future.\nRisk models are to output a prediction which is expressed relative to the expected value for the given driver setting.\x0c4.c.i Driver Score\nDriver score is computed for each driver at a regular interval, such as daily. Every day we refresh the driver’s data window, make a new risk prediction (if necessary) and then map that\nprediction to a score using a mapping of risk → score.\nThe risk → score mapping can be updated but is expected to be slow changing.\n', 'content_type': 'text', 'score': 0.07068779, 'meta': {'_split_id': 2}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '85efa80d-6fb7-03f3-e47f-e09541b7ffac'}>, <Document: {'content': 'The proposed mapping is constructed from a large dataset of driver scores (historic data across all fleets has been used for the first mapping) as follows:\nThe lowest percentile of observed risk corresponds to a score of 100\nThe highest percentile of observed risk corresponds to a score of 1\nDivide the range between the 1st and 99th percentile of risk into 98 equal-width bins\nThis process yields a binned lookup table mapping from risk to score.\n4.c.ii Fleet Score\nWe define fleet score as a representation of a prediction about the future risk of the fleet given historic behaviour. It is important that fleet score is related to driver score in as direct and\nintuitive way as possible, so that it is easy for customers to understand, notably without referencing the unbounded risk prediction underlying the score. This last restriction protects us\nfrom the fleet score becoming opaque and ensures that driver scores and fleet score are aligned.\nTo make a prediction about the future risk of the fleet, we need to consider two aspects\n1. The risk of the individual drivers who comprise the fleet (this is represented by driver score)\n2. The expected distribution of the fleet’s future mileage amongst its drivers\nThis second point is important. It is not sufficient to just take the fleet’s average driver score and call that the fleet score. What if the best drivers drive twice as much as the worst ones?\nSo, we make a prediction about the future distribution of mileage amongst the drivers and use this as a weight in the average: Fleet score is therefore average driver score, weighted by\ndriver mileage.\nWe will stop referring to Trip Score entirely. This is because trips on their own do not contain enough information (in our current representation of our data input) to give stable risk\npredictions.\nLet fleet_score_{i,t} be the fleet score for fleet i at time t .\nLet driver_score_{i, j, t} be the driver score for driver j in fleet i at time t\x0cImplicit in this definition is that we are taking our prediction of the future mileage distribution of the fleet from its recent mileage mix. If a given driver drove 10% of the fleet’s miles in the\npast 30 days, then we expect them to continue to make a similar contribution, so their score is weighted in the aggregation by 10%. This is a naive way of making the mileage distribution\nprediction but it is as simple and intuitive.\n4.d Pricing\nThe proposal requires a fixed score → rating map for each fleet. This is so that a fleet can know what discounts or loadings are applicable for a given score before they start.\nWe propose that the score → rating map should be fixed at quote time. It may be universal or may depend on some fleet attributes that are available at time of quote, such as the\nmajority setting we expect to observe the drivers in.\n', 'content_type': 'text', 'score': 0.033972, 'meta': {'_split_id': 3}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6cd2e7cf-4ad3-032c-a3c2-da8d53861889'}>, <Document: {'content': '4.d.i Determining Rating Multipliers from Score\nFor fitting the score → rating mapping for a given setting, we propose to fit a curve which is parametrised to ensure a net-zero rating across the portfolio (accounting for variations in\ndriver exposure). An example is shown below.\nLet window_size be the size of our scoring window in days (e.g. 30)\nLet mileage_{i, j, t, t-window_size} be the distance driven by driver j in fleet i between time t-window_size and t .\nThen\nfleet_score_{i, t} = wavg(driver_score_{i, j, t}, w=mileage_{i, j, t, t-window_size})\x0cMore details on parametrisation of this curve are discussed in this notebook.\n4.d.ii Alternative Pricing Tables\nGiven the proposed scoring structure, it is possible to determine a variety of pricing schemes which can fit different products. The example above is produced by the two constraints:\nMultiplicative rating is bounded between ±20%\nPortfolio effect of dynamic pricing (assuming constant behaviour) is 0\nSome alternative constraint sets which we may wish to consider (to facilitate other products) are:\nDiscount only\nMultiplicative rating is bounded between 0 and -10%\nPortfolio effect of dynamic pricing (assuming constant behaviour) is 0\nNeutral zone\nMultiplicative rating is bounded between ±20%\nScores within ±5 points of the neutral score should have no adjustment\nPortfolio effect of dynamic pricing (assuming constant behaviour) is 0\nTo fit a price → rating curve for any of these constraints, one has to simply take the historic scores and base premiums and find the parameters which satisfy them. The historic score and\nbase premium dataset\n5. Appendices\nAppendix A. Algorithms\nAppendix B: Pilot\nAppendix C: Assets\nAppendix D: RiskOS Integration\nAppendix E: User Experience Impact\nAppendix F: Onboarding Impact\nAppendix G: BenScoPe vs. Status Quo Head-to-Head\nAppendix H: Scoring and Pricing Customer Impact Analysis\nBenScoPe: How is My Premium Calculated? (PHYD)\nBenScoPe: How is My Premium Calculated? (Annual Plus)', 'content_type': 'text', 'score': 0.023689471, 'meta': {'_split_id': 4}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e0ab4244-e71f-113c-cfe1-94fb0fd52e52'}>, <Document: {'content': 'Absolute Driver Scoring (BenScoPe)\nThis Confluence page documents a proposal known as BenScoPe, which seeks to reform our benchmarking, scoring and pricing that underpins our two current Rideshur products.\nWe describe a scoring structure which can be used for delivering driver and fleet risk scores which are comparable and transferable between contexts, and which do not require the\nmaintenance of a benchmark for any given fleet.\nThe changes described here have implications for how our users will interact with the products based upon this new scoring system. These implications are out of scope for the proposal,\nbut are discussed to some degree in the appendix pages.\nContents\n1. Motivation\n2. Scope\na. Problem Statement\nb. Proposal Summary\n3. Benefits and Risks\n4. Proposal\na. Risk/Score/Price structure, incl. base model (UW)\nb. Risk modelling (incl. setting groups)\ni. Windowing\nii. Normalisation\niii. Risk Prediction Aggregation\nc. Scoring\ni. Driver Score\nii. Fleet Score\nd. Pricing\ni. Determining rating multipliers from score\nii. Alternative Pricing Tables\n5. Appendices\na. Algorithms\nb. Pilot\nc. Assets\nd. RiskOS Integration\ne. User Experience Impact\nf. Onboarding Impact\ng. BenScoPe vs. Status Quo Head-to-Head\n1. Motivation\nOur current scoring system is not delivering for customers or for Humn. For customers, the score is not providing a good enough risk measurement or a fair pricing response. For Humn,\nthe operational costs around onboarding are unsustainable and also impact our customers.\nAn enumeration of the main issues follows.\n1. Our scores are not absolute, only relative.\na. Most fleet scores hover uninspiringly around 50\nb. We can’t compare fleets to each other\nc. We can’t compare drivers from different fleets\n2. Our benchmarking process is flawed and slow\na. It delays onboarding\nb. The behaviour we observe during benchmarking may not be representative\nc. It creates a lot of day-to-day operational work, especially for the Data Science team, who make the benchmarking measurement\n3. Our risk modelling is complex, retrospective and inefficient\na. Making risk predictions at the trip level is volatile, and mitigation of this has introduced complexity\nb. Interventions can only be made at the driver level, so the focus on single trips is an error\nc. There is no need to make online predictions in order to do online pricing\n2. Scope\nThe Rideshur dynamic scoring and pricing system is the scope of this proposal.\n2.a Problem Statement\nThe system we are considering changing here aims to meet two goals\x0c1. Accurately measure risk\n2. Help customers reduce risk\n3. Collect the right amount of money to hit a given loss ratio target\nThe problem statement is therefore:\n2.b Proposal Summary\n1. No more benchmarking\n2. Risk modelling and scores made at driver level, published daily\n3. Fleet score is the average of driver scores, weighted by mileage, published daily\n4. Scores are absolute and do not depend on fleet\n5. Use a score → rating map to transform a score into a discount/loading. This can be universal or fleet specific\n6. ', 'content_type': 'text', 'score': 0.01572399, 'meta': {'_split_id': 0}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1d43e2e3-6114-32c7-d82f-8598abce23f6'}>, <Document: {'content': 'Use setting groups to normalise risk model outputs across different settings such as driving in vans vs driving in cars\n3. Benefits and Risks\nThe proposal aims to deliver the following benefits\nWe have identified the following risks\n4. Proposal\n4.a Base Model and Dynamic Model\nWe do not propose to change the relationship between the base model (owned by Underwriting) and the dynamic model (owned by Data Science).\nBase model provides a base price for a given fleet\nDynamic model provides a multiplicative adjustment to the base price, within the bounds of ±20%\n4.b Risk modelling\nThere are two main changes proposed here. The first is to use a window of past driver behaviour to make a risk estimate about the driver’s future behaviour. This is a deviation from our\ncurrent method of making risk estimates retrospectively at the trip level. The volatility of making retrospective estimates of risk at trip-level is illustrated here, which plots the trip scores for\na single driver over a week-long period.\nThe second change is to introduce a normalisation layer to the output of our models so that the risk estimate is given in relation to the average risk estimated over historic data.\nGiven some telematics data for a set of customers, provide:\nA score which accurately represents the risk in a way understandable and actionable for customers\nA corresponding pricing adjustment which is fair, cost-neutral and promotes improvements in behaviour with respect to risk.\nRemove the uncertainty and operational cost of benchmarking\nScores become more interpretable and have meaning in multiple contexts\nTrips no longer need to be scored individually, so we have the option to decrease load on our scoring pipeline by using batch computations instead\nA flexible framework for converting scores into prices that can accommodate more complexity as our datasets grow\nWe may collect less than the quoted premium for fleets who are less risky. This is because the system will respond more directly to behavioural change\nThere is no guarantee that a fleet will start their policy with a neutral score or rating (as is currently the case). This has the potential for a bad user experience in some cases so\nwe must try and handle this issue\nWe will no longer calculate risk estimates at the trip level and instead focus on making driver-level risk predictions about the future.\x0c4.b.i Driver Settings\nWe introduce the concept of driver settings, which are arbitrary groupings allowing us to control for different contexts in which the risk models may respond differently. For example, two\nsettings in which we might observe a driver are van and car . We propose to handle the behaviour in each setting separately, aggregating it up to the driver level after a normalisation\nstep.\nNote that driver settings can be used for more complex groupings in future if we wish, controlling for aspects other than vehicle type, such as business type.\n', 'content_type': 'text', 'score': 0.0062655336, 'meta': {'_split_id': 1}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5ac6e8ee-98b1-7f4e-ea4f-4cf184155fea'}>], 'answers': [<Answer {'answer': 'The documents do not provide information on how Revolut would be impacted by AIG going bankrupt.', 'type': 'generative', 'score': None, 'context': None, 'offsets_in_document': None, 'offsets_in_context': None, 'document_ids': ['85efa80d-6fb7-03f3-e47f-e09541b7ffac', '6cd2e7cf-4ad3-032c-a3c2-da8d53861889', 'e0ab4244-e71f-113c-cfe1-94fb0fd52e52', '1d43e2e3-6114-32c7-d82f-8598abce23f6', '5ac6e8ee-98b1-7f4e-ea4f-4cf184155fea'], 'meta': {'prompt': 'Given the provided Documents, answer the Query.\n\n                                                Query: How would Revolut be impacted by AIG going bankrupt?\n\n                                                Documents: 4.b.i Windowing\nTo obtain a risk prediction for a given driver, first establish when their most recent trip occurred. Retrieve a historic dataset of their behaviour looking back from this most recent trip. This\nhistoric dataset is the driver window.\nWe propose that the window size is 30 days.\nNote that we will probably need to impose a minimum distance on this window, such as 250km of driving, to ensure some stability in the score. We can use this minimum distance as\nthe requirement for giving drivers their first driver score, which means we do not have to wait for the full 30 days before a driver or fleet can get their score.\n4.b.ii Normalisation\nWe normalise the output of the risk models such that, for each driver setting group, the expected output of the model across all drivers, weighted by their mileage, is 1. This gives us a\nconcept of relative risk for our risk models.\n4.b.iii Risk Prediction Aggregation\nRisk predictions are made at the driver setting level. That is, for each driver, we retrieve their window of driving behaviour and split it up into the setting groups. For each setting, we\naggregate the data and make a risk prediction (using the risk models) on this aggregation. Then for each driver, we aggregate up the setting-level risk predictions using a simple average,\nweighted by mileage observed in each setting.\nA pipeline (expanded to include the scoring step) of this process is illustrated below.\n4.c Scoring\nThe purpose of scoring is to convert a relative risk prediction from being an unbounded, real-valued number to an integer in a fixed range familiar to our users. Ratings from 1-100 are\ncommonplace in everyday life, so we use this as our target range.\nWe propose to provide scores at two levels only:\n1. Driver Score: This represents our current prediction about the future risk of a driver\n2. Fleet Score: This represents our current prediction about the future risk of a fleet\nIt may be preferable to use a window size based on mileage rather than time, or has some more complicated logic determining what information is included. This is not expected\nto change the majority of risk predictions but is reserved as a topic for exploration by the Data Science team in future.\nRisk models are to output a prediction which is expressed relative to the expected value for the given driver setting.\x0c4.c.i Driver Score\nDriver score is computed for each driver at a regular interval, such as daily. Every day we refresh the driver’s data window, make a new risk prediction (if necessary) and then map that\nprediction to a score using a mapping of risk → score.\nThe risk → score mapping can be updated but is expected to be slow changing.\n The proposed mapping is constructed from a large dataset of driver scores (historic data across all fleets has been used for the first mapping) as follows:\nThe lowest percentile of observed risk corresponds to a score of 100\nThe highest percentile of observed risk corresponds to a score of 1\nDivide the range between the 1st and 99th percentile of risk into 98 equal-width bins\nThis process yields a binned lookup table mapping from risk to score.\n4.c.ii Fleet Score\nWe define fleet score as a representation of a prediction about the future risk of the fleet given historic behaviour. It is important that fleet score is related to driver score in as direct and\nintuitive way as possible, so that it is easy for customers to understand, notably without referencing the unbounded risk prediction underlying the score. This last restriction protects us\nfrom the fleet score becoming opaque and ensures that driver scores and fleet score are aligned.\nTo make a prediction about the future risk of the fleet, we need to consider two aspects\n1. The risk of the individual drivers who comprise the fleet (this is represented by driver score)\n2. The expected distribution of the fleet’s future mileage amongst its drivers\nThis second point is important. It is not sufficient to just take the fleet’s average driver score and call that the fleet score. What if the best drivers drive twice as much as the worst ones?\nSo, we make a prediction about the future distribution of mileage amongst the drivers and use this as a weight in the average: Fleet score is therefore average driver score, weighted by\ndriver mileage.\nWe will stop referring to Trip Score entirely. This is because trips on their own do not contain enough information (in our current representation of our data input) to give stable risk\npredictions.\nLet fleet_score_{i,t} be the fleet score for fleet i at time t .\nLet driver_score_{i, j, t} be the driver score for driver j in fleet i at time t\x0cImplicit in this definition is that we are taking our prediction of the future mileage distribution of the fleet from its recent mileage mix. If a given driver drove 10% of the fleet’s miles in the\npast 30 days, then we expect them to continue to make a similar contribution, so their score is weighted in the aggregation by 10%. This is a naive way of making the mileage distribution\nprediction but it is as simple and intuitive.\n4.d Pricing\nThe proposal requires a fixed score → rating map for each fleet. This is so that a fleet can know what discounts or loadings are applicable for a given score before they start.\nWe propose that the score → rating map should be fixed at quote time. It may be universal or may depend on some fleet attributes that are available at time of quote, such as the\nmajority setting we expect to observe the drivers in.\n 4.d.i Determining Rating Multipliers from Score\nFor fitting the score → rating mapping for a given setting, we propose to fit a curve which is parametrised to ensure a net-zero rating across the portfolio (accounting for variations in\ndriver exposure). An example is shown below.\nLet window_size be the size of our scoring window in days (e.g. 30)\nLet mileage_{i, j, t, t-window_size} be the distance driven by driver j in fleet i between time t-window_size and t .\nThen\nfleet_score_{i, t} = wavg(driver_score_{i, j, t}, w=mileage_{i, j, t, t-window_size})\x0cMore details on parametrisation of this curve are discussed in this notebook.\n4.d.ii Alternative Pricing Tables\nGiven the proposed scoring structure, it is possible to determine a variety of pricing schemes which can fit different products. The example above is produced by the two constraints:\nMultiplicative rating is bounded between ±20%\nPortfolio effect of dynamic pricing (assuming constant behaviour) is 0\nSome alternative constraint sets which we may wish to consider (to facilitate other products) are:\nDiscount only\nMultiplicative rating is bounded between 0 and -10%\nPortfolio effect of dynamic pricing (assuming constant behaviour) is 0\nNeutral zone\nMultiplicative rating is bounded between ±20%\nScores within ±5 points of the neutral score should have no adjustment\nPortfolio effect of dynamic pricing (assuming constant behaviour) is 0\nTo fit a price → rating curve for any of these constraints, one has to simply take the historic scores and base premiums and find the parameters which satisfy them. The historic score and\nbase premium dataset\n5. Appendices\nAppendix A. Algorithms\nAppendix B: Pilot\nAppendix C: Assets\nAppendix D: RiskOS Integration\nAppendix E: User Experience Impact\nAppendix F: Onboarding Impact\nAppendix G: BenScoPe vs. Status Quo Head-to-Head\nAppendix H: Scoring and Pricing Customer Impact Analysis\nBenScoPe: How is My Premium Calculated? (PHYD)\nBenScoPe: How is My Premium Calculated? (Annual Plus) Absolute Driver Scoring (BenScoPe)\nThis Confluence page documents a proposal known as BenScoPe, which seeks to reform our benchmarking, scoring and pricing that underpins our two current Rideshur products.\nWe describe a scoring structure which can be used for delivering driver and fleet risk scores which are comparable and transferable between contexts, and which do not require the\nmaintenance of a benchmark for any given fleet.\nThe changes described here have implications for how our users will interact with the products based upon this new scoring system. These implications are out of scope for the proposal,\nbut are discussed to some degree in the appendix pages.\nContents\n1. Motivation\n2. Scope\na. Problem Statement\nb. Proposal Summary\n3. Benefits and Risks\n4. Proposal\na. Risk/Score/Price structure, incl. base model (UW)\nb. Risk modelling (incl. setting groups)\ni. Windowing\nii. Normalisation\niii. Risk Prediction Aggregation\nc. Scoring\ni. Driver Score\nii. Fleet Score\nd. Pricing\ni. Determining rating multipliers from score\nii. Alternative Pricing Tables\n5. Appendices\na. Algorithms\nb. Pilot\nc. Assets\nd. RiskOS Integration\ne. User Experience Impact\nf. Onboarding Impact\ng. BenScoPe vs. Status Quo Head-to-Head\n1. Motivation\nOur current scoring system is not delivering for customers or for Humn. For customers, the score is not providing a good enough risk measurement or a fair pricing response. For Humn,\nthe operational costs around onboarding are unsustainable and also impact our customers.\nAn enumeration of the main issues follows.\n1. Our scores are not absolute, only relative.\na. Most fleet scores hover uninspiringly around 50\nb. We can’t compare fleets to each other\nc. We can’t compare drivers from different fleets\n2. Our benchmarking process is flawed and slow\na. It delays onboarding\nb. The behaviour we observe during benchmarking may not be representative\nc. It creates a lot of day-to-day operational work, especially for the Data Science team, who make the benchmarking measurement\n3. Our risk modelling is complex, retrospective and inefficient\na. Making risk predictions at the trip level is volatile, and mitigation of this has introduced complexity\nb. Interventions can only be made at the driver level, so the focus on single trips is an error\nc. There is no need to make online predictions in order to do online pricing\n2. Scope\nThe Rideshur dynamic scoring and pricing system is the scope of this proposal.\n2.a Problem Statement\nThe system we are considering changing here aims to meet two goals\x0c1. Accurately measure risk\n2. Help customers reduce risk\n3. Collect the right amount of money to hit a given loss ratio target\nThe problem statement is therefore:\n2.b Proposal Summary\n1. No more benchmarking\n2. Risk modelling and scores made at driver level, published daily\n3. Fleet score is the average of driver scores, weighted by mileage, published daily\n4. Scores are absolute and do not depend on fleet\n5. Use a score → rating map to transform a score into a discount/loading. This can be universal or fleet specific\n6.  Use setting groups to normalise risk model outputs across different settings such as driving in vans vs driving in cars\n3. Benefits and Risks\nThe proposal aims to deliver the following benefits\nWe have identified the following risks\n4. Proposal\n4.a Base Model and Dynamic Model\nWe do not propose to change the relationship between the base model (owned by Underwriting) and the dynamic model (owned by Data Science).\nBase model provides a base price for a given fleet\nDynamic model provides a multiplicative adjustment to the base price, within the bounds of ±20%\n4.b Risk modelling\nThere are two main changes proposed here. The first is to use a window of past driver behaviour to make a risk estimate about the driver’s future behaviour. This is a deviation from our\ncurrent method of making risk estimates retrospectively at the trip level. The volatility of making retrospective estimates of risk at trip-level is illustrated here, which plots the trip scores for\na single driver over a week-long period.\nThe second change is to introduce a normalisation layer to the output of our models so that the risk estimate is given in relation to the average risk estimated over historic data.\nGiven some telematics data for a set of customers, provide:\nA score which accurately represents the risk in a way understandable and actionable for customers\nA corresponding pricing adjustment which is fair, cost-neutral and promotes improvements in behaviour with respect to risk.\nRemove the uncertainty and operational cost of benchmarking\nScores become more interpretable and have meaning in multiple contexts\nTrips no longer need to be scored individually, so we have the option to decrease load on our scoring pipeline by using batch computations instead\nA flexible framework for converting scores into prices that can accommodate more complexity as our datasets grow\nWe may collect less than the quoted premium for fleets who are less risky. This is because the system will respond more directly to behavioural change\nThere is no guarantee that a fleet will start their policy with a neutral score or rating (as is currently the case). This has the potential for a bad user experience in some cases so\nwe must try and handle this issue\nWe will no longer calculate risk estimates at the trip level and instead focus on making driver-level risk predictions about the future.\x0c4.b.i Driver Settings\nWe introduce the concept of driver settings, which are arbitrary groupings allowing us to control for different contexts in which the risk models may respond differently. For example, two\nsettings in which we might observe a driver are van and car . We propose to handle the behaviour in each setting separately, aggregating it up to the driver level after a normalisation\nstep.\nNote that driver settings can be used for more complex groupings in future if we wish, controlling for aspects other than vehicle type, such as business type.\n\n                                                Answer: \n                                            '}}>], 'prompts': ['Given the provided Documents, answer the Query.\n\n                                                Query: How would Revolut be impacted by AIG going bankrupt?\n\n                                                Documents: 4.b.i Windowing\nTo obtain a risk prediction for a given driver, first establish when their most recent trip occurred. Retrieve a historic dataset of their behaviour looking back from this most recent trip. This\nhistoric dataset is the driver window.\nWe propose that the window size is 30 days.\nNote that we will probably need to impose a minimum distance on this window, such as 250km of driving, to ensure some stability in the score. We can use this minimum distance as\nthe requirement for giving drivers their first driver score, which means we do not have to wait for the full 30 days before a driver or fleet can get their score.\n4.b.ii Normalisation\nWe normalise the output of the risk models such that, for each driver setting group, the expected output of the model across all drivers, weighted by their mileage, is 1. This gives us a\nconcept of relative risk for our risk models.\n4.b.iii Risk Prediction Aggregation\nRisk predictions are made at the driver setting level. That is, for each driver, we retrieve their window of driving behaviour and split it up into the setting groups. For each setting, we\naggregate the data and make a risk prediction (using the risk models) on this aggregation. Then for each driver, we aggregate up the setting-level risk predictions using a simple average,\nweighted by mileage observed in each setting.\nA pipeline (expanded to include the scoring step) of this process is illustrated below.\n4.c Scoring\nThe purpose of scoring is to convert a relative risk prediction from being an unbounded, real-valued number to an integer in a fixed range familiar to our users. Ratings from 1-100 are\ncommonplace in everyday life, so we use this as our target range.\nWe propose to provide scores at two levels only:\n1. Driver Score: This represents our current prediction about the future risk of a driver\n2. Fleet Score: This represents our current prediction about the future risk of a fleet\nIt may be preferable to use a window size based on mileage rather than time, or has some more complicated logic determining what information is included. This is not expected\nto change the majority of risk predictions but is reserved as a topic for exploration by the Data Science team in future.\nRisk models are to output a prediction which is expressed relative to the expected value for the given driver setting.\x0c4.c.i Driver Score\nDriver score is computed for each driver at a regular interval, such as daily. Every day we refresh the driver’s data window, make a new risk prediction (if necessary) and then map that\nprediction to a score using a mapping of risk → score.\nThe risk → score mapping can be updated but is expected to be slow changing.\n The proposed mapping is constructed from a large dataset of driver scores (historic data across all fleets has been used for the first mapping) as follows:\nThe lowest percentile of observed risk corresponds to a score of 100\nThe highest percentile of observed risk corresponds to a score of 1\nDivide the range between the 1st and 99th percentile of risk into 98 equal-width bins\nThis process yields a binned lookup table mapping from risk to score.\n4.c.ii Fleet Score\nWe define fleet score as a representation of a prediction about the future risk of the fleet given historic behaviour. It is important that fleet score is related to driver score in as direct and\nintuitive way as possible, so that it is easy for customers to understand, notably without referencing the unbounded risk prediction underlying the score. This last restriction protects us\nfrom the fleet score becoming opaque and ensures that driver scores and fleet score are aligned.\nTo make a prediction about the future risk of the fleet, we need to consider two aspects\n1. The risk of the individual drivers who comprise the fleet (this is represented by driver score)\n2. The expected distribution of the fleet’s future mileage amongst its drivers\nThis second point is important. It is not sufficient to just take the fleet’s average driver score and call that the fleet score. What if the best drivers drive twice as much as the worst ones?\nSo, we make a prediction about the future distribution of mileage amongst the drivers and use this as a weight in the average: Fleet score is therefore average driver score, weighted by\ndriver mileage.\nWe will stop referring to Trip Score entirely. This is because trips on their own do not contain enough information (in our current representation of our data input) to give stable risk\npredictions.\nLet fleet_score_{i,t} be the fleet score for fleet i at time t .\nLet driver_score_{i, j, t} be the driver score for driver j in fleet i at time t\x0cImplicit in this definition is that we are taking our prediction of the future mileage distribution of the fleet from its recent mileage mix. If a given driver drove 10% of the fleet’s miles in the\npast 30 days, then we expect them to continue to make a similar contribution, so their score is weighted in the aggregation by 10%. This is a naive way of making the mileage distribution\nprediction but it is as simple and intuitive.\n4.d Pricing\nThe proposal requires a fixed score → rating map for each fleet. This is so that a fleet can know what discounts or loadings are applicable for a given score before they start.\nWe propose that the score → rating map should be fixed at quote time. It may be universal or may depend on some fleet attributes that are available at time of quote, such as the\nmajority setting we expect to observe the drivers in.\n 4.d.i Determining Rating Multipliers from Score\nFor fitting the score → rating mapping for a given setting, we propose to fit a curve which is parametrised to ensure a net-zero rating across the portfolio (accounting for variations in\ndriver exposure). An example is shown below.\nLet window_size be the size of our scoring window in days (e.g. 30)\nLet mileage_{i, j, t, t-window_size} be the distance driven by driver j in fleet i between time t-window_size and t .\nThen\nfleet_score_{i, t} = wavg(driver_score_{i, j, t}, w=mileage_{i, j, t, t-window_size})\x0cMore details on parametrisation of this curve are discussed in this notebook.\n4.d.ii Alternative Pricing Tables\nGiven the proposed scoring structure, it is possible to determine a variety of pricing schemes which can fit different products. The example above is produced by the two constraints:\nMultiplicative rating is bounded between ±20%\nPortfolio effect of dynamic pricing (assuming constant behaviour) is 0\nSome alternative constraint sets which we may wish to consider (to facilitate other products) are:\nDiscount only\nMultiplicative rating is bounded between 0 and -10%\nPortfolio effect of dynamic pricing (assuming constant behaviour) is 0\nNeutral zone\nMultiplicative rating is bounded between ±20%\nScores within ±5 points of the neutral score should have no adjustment\nPortfolio effect of dynamic pricing (assuming constant behaviour) is 0\nTo fit a price → rating curve for any of these constraints, one has to simply take the historic scores and base premiums and find the parameters which satisfy them. The historic score and\nbase premium dataset\n5. Appendices\nAppendix A. Algorithms\nAppendix B: Pilot\nAppendix C: Assets\nAppendix D: RiskOS Integration\nAppendix E: User Experience Impact\nAppendix F: Onboarding Impact\nAppendix G: BenScoPe vs. Status Quo Head-to-Head\nAppendix H: Scoring and Pricing Customer Impact Analysis\nBenScoPe: How is My Premium Calculated? (PHYD)\nBenScoPe: How is My Premium Calculated? (Annual Plus) Absolute Driver Scoring (BenScoPe)\nThis Confluence page documents a proposal known as BenScoPe, which seeks to reform our benchmarking, scoring and pricing that underpins our two current Rideshur products.\nWe describe a scoring structure which can be used for delivering driver and fleet risk scores which are comparable and transferable between contexts, and which do not require the\nmaintenance of a benchmark for any given fleet.\nThe changes described here have implications for how our users will interact with the products based upon this new scoring system. These implications are out of scope for the proposal,\nbut are discussed to some degree in the appendix pages.\nContents\n1. Motivation\n2. Scope\na. Problem Statement\nb. Proposal Summary\n3. Benefits and Risks\n4. Proposal\na. Risk/Score/Price structure, incl. base model (UW)\nb. Risk modelling (incl. setting groups)\ni. Windowing\nii. Normalisation\niii. Risk Prediction Aggregation\nc. Scoring\ni. Driver Score\nii. Fleet Score\nd. Pricing\ni. Determining rating multipliers from score\nii. Alternative Pricing Tables\n5. Appendices\na. Algorithms\nb. Pilot\nc. Assets\nd. RiskOS Integration\ne. User Experience Impact\nf. Onboarding Impact\ng. BenScoPe vs. Status Quo Head-to-Head\n1. Motivation\nOur current scoring system is not delivering for customers or for Humn. For customers, the score is not providing a good enough risk measurement or a fair pricing response. For Humn,\nthe operational costs around onboarding are unsustainable and also impact our customers.\nAn enumeration of the main issues follows.\n1. Our scores are not absolute, only relative.\na. Most fleet scores hover uninspiringly around 50\nb. We can’t compare fleets to each other\nc. We can’t compare drivers from different fleets\n2. Our benchmarking process is flawed and slow\na. It delays onboarding\nb. The behaviour we observe during benchmarking may not be representative\nc. It creates a lot of day-to-day operational work, especially for the Data Science team, who make the benchmarking measurement\n3. Our risk modelling is complex, retrospective and inefficient\na. Making risk predictions at the trip level is volatile, and mitigation of this has introduced complexity\nb. Interventions can only be made at the driver level, so the focus on single trips is an error\nc. There is no need to make online predictions in order to do online pricing\n2. Scope\nThe Rideshur dynamic scoring and pricing system is the scope of this proposal.\n2.a Problem Statement\nThe system we are considering changing here aims to meet two goals\x0c1. Accurately measure risk\n2. Help customers reduce risk\n3. Collect the right amount of money to hit a given loss ratio target\nThe problem statement is therefore:\n2.b Proposal Summary\n1. No more benchmarking\n2. Risk modelling and scores made at driver level, published daily\n3. Fleet score is the average of driver scores, weighted by mileage, published daily\n4. Scores are absolute and do not depend on fleet\n5. Use a score → rating map to transform a score into a discount/loading. This can be universal or fleet specific\n6.  Use setting groups to normalise risk model outputs across different settings such as driving in vans vs driving in cars\n3. Benefits and Risks\nThe proposal aims to deliver the following benefits\nWe have identified the following risks\n4. Proposal\n4.a Base Model and Dynamic Model\nWe do not propose to change the relationship between the base model (owned by Underwriting) and the dynamic model (owned by Data Science).\nBase model provides a base price for a given fleet\nDynamic model provides a multiplicative adjustment to the base price, within the bounds of ±20%\n4.b Risk modelling\nThere are two main changes proposed here. The first is to use a window of past driver behaviour to make a risk estimate about the driver’s future behaviour. This is a deviation from our\ncurrent method of making risk estimates retrospectively at the trip level. The volatility of making retrospective estimates of risk at trip-level is illustrated here, which plots the trip scores for\na single driver over a week-long period.\nThe second change is to introduce a normalisation layer to the output of our models so that the risk estimate is given in relation to the average risk estimated over historic data.\nGiven some telematics data for a set of customers, provide:\nA score which accurately represents the risk in a way understandable and actionable for customers\nA corresponding pricing adjustment which is fair, cost-neutral and promotes improvements in behaviour with respect to risk.\nRemove the uncertainty and operational cost of benchmarking\nScores become more interpretable and have meaning in multiple contexts\nTrips no longer need to be scored individually, so we have the option to decrease load on our scoring pipeline by using batch computations instead\nA flexible framework for converting scores into prices that can accommodate more complexity as our datasets grow\nWe may collect less than the quoted premium for fleets who are less risky. This is because the system will respond more directly to behavioural change\nThere is no guarantee that a fleet will start their policy with a neutral score or rating (as is currently the case). This has the potential for a bad user experience in some cases so\nwe must try and handle this issue\nWe will no longer calculate risk estimates at the trip level and instead focus on making driver-level risk predictions about the future.\x0c4.b.i Driver Settings\nWe introduce the concept of driver settings, which are arbitrary groupings allowing us to control for different contexts in which the risk models may respond differently. For example, two\nsettings in which we might observe a driver are van and car . We propose to handle the behaviour in each setting separately, aggregating it up to the driver level after a normalisation\nstep.\nNote that driver settings can be used for more complex groupings in future if we wish, controlling for aspects other than vehicle type, such as business type.\n\n                                                Answer: \n                                            ']}, 'documents': [<Document: {'content': '4.b.i Windowing\nTo obtain a risk prediction for a given driver, first establish when their most recent trip occurred. Retrieve a historic dataset of their behaviour looking back from this most recent trip. This\nhistoric dataset is the driver window.\nWe propose that the window size is 30 days.\nNote that we will probably need to impose a minimum distance on this window, such as 250km of driving, to ensure some stability in the score. We can use this minimum distance as\nthe requirement for giving drivers their first driver score, which means we do not have to wait for the full 30 days before a driver or fleet can get their score.\n4.b.ii Normalisation\nWe normalise the output of the risk models such that, for each driver setting group, the expected output of the model across all drivers, weighted by their mileage, is 1. This gives us a\nconcept of relative risk for our risk models.\n4.b.iii Risk Prediction Aggregation\nRisk predictions are made at the driver setting level. That is, for each driver, we retrieve their window of driving behaviour and split it up into the setting groups. For each setting, we\naggregate the data and make a risk prediction (using the risk models) on this aggregation. Then for each driver, we aggregate up the setting-level risk predictions using a simple average,\nweighted by mileage observed in each setting.\nA pipeline (expanded to include the scoring step) of this process is illustrated below.\n4.c Scoring\nThe purpose of scoring is to convert a relative risk prediction from being an unbounded, real-valued number to an integer in a fixed range familiar to our users. Ratings from 1-100 are\ncommonplace in everyday life, so we use this as our target range.\nWe propose to provide scores at two levels only:\n1. Driver Score: This represents our current prediction about the future risk of a driver\n2. Fleet Score: This represents our current prediction about the future risk of a fleet\nIt may be preferable to use a window size based on mileage rather than time, or has some more complicated logic determining what information is included. This is not expected\nto change the majority of risk predictions but is reserved as a topic for exploration by the Data Science team in future.\nRisk models are to output a prediction which is expressed relative to the expected value for the given driver setting.\x0c4.c.i Driver Score\nDriver score is computed for each driver at a regular interval, such as daily. Every day we refresh the driver’s data window, make a new risk prediction (if necessary) and then map that\nprediction to a score using a mapping of risk → score.\nThe risk → score mapping can be updated but is expected to be slow changing.\n', 'content_type': 'text', 'score': 0.07068779, 'meta': {'_split_id': 2}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '85efa80d-6fb7-03f3-e47f-e09541b7ffac'}>, <Document: {'content': 'The proposed mapping is constructed from a large dataset of driver scores (historic data across all fleets has been used for the first mapping) as follows:\nThe lowest percentile of observed risk corresponds to a score of 100\nThe highest percentile of observed risk corresponds to a score of 1\nDivide the range between the 1st and 99th percentile of risk into 98 equal-width bins\nThis process yields a binned lookup table mapping from risk to score.\n4.c.ii Fleet Score\nWe define fleet score as a representation of a prediction about the future risk of the fleet given historic behaviour. It is important that fleet score is related to driver score in as direct and\nintuitive way as possible, so that it is easy for customers to understand, notably without referencing the unbounded risk prediction underlying the score. This last restriction protects us\nfrom the fleet score becoming opaque and ensures that driver scores and fleet score are aligned.\nTo make a prediction about the future risk of the fleet, we need to consider two aspects\n1. The risk of the individual drivers who comprise the fleet (this is represented by driver score)\n2. The expected distribution of the fleet’s future mileage amongst its drivers\nThis second point is important. It is not sufficient to just take the fleet’s average driver score and call that the fleet score. What if the best drivers drive twice as much as the worst ones?\nSo, we make a prediction about the future distribution of mileage amongst the drivers and use this as a weight in the average: Fleet score is therefore average driver score, weighted by\ndriver mileage.\nWe will stop referring to Trip Score entirely. This is because trips on their own do not contain enough information (in our current representation of our data input) to give stable risk\npredictions.\nLet fleet_score_{i,t} be the fleet score for fleet i at time t .\nLet driver_score_{i, j, t} be the driver score for driver j in fleet i at time t\x0cImplicit in this definition is that we are taking our prediction of the future mileage distribution of the fleet from its recent mileage mix. If a given driver drove 10% of the fleet’s miles in the\npast 30 days, then we expect them to continue to make a similar contribution, so their score is weighted in the aggregation by 10%. This is a naive way of making the mileage distribution\nprediction but it is as simple and intuitive.\n4.d Pricing\nThe proposal requires a fixed score → rating map for each fleet. This is so that a fleet can know what discounts or loadings are applicable for a given score before they start.\nWe propose that the score → rating map should be fixed at quote time. It may be universal or may depend on some fleet attributes that are available at time of quote, such as the\nmajority setting we expect to observe the drivers in.\n', 'content_type': 'text', 'score': 0.033972, 'meta': {'_split_id': 3}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6cd2e7cf-4ad3-032c-a3c2-da8d53861889'}>, <Document: {'content': '4.d.i Determining Rating Multipliers from Score\nFor fitting the score → rating mapping for a given setting, we propose to fit a curve which is parametrised to ensure a net-zero rating across the portfolio (accounting for variations in\ndriver exposure). An example is shown below.\nLet window_size be the size of our scoring window in days (e.g. 30)\nLet mileage_{i, j, t, t-window_size} be the distance driven by driver j in fleet i between time t-window_size and t .\nThen\nfleet_score_{i, t} = wavg(driver_score_{i, j, t}, w=mileage_{i, j, t, t-window_size})\x0cMore details on parametrisation of this curve are discussed in this notebook.\n4.d.ii Alternative Pricing Tables\nGiven the proposed scoring structure, it is possible to determine a variety of pricing schemes which can fit different products. The example above is produced by the two constraints:\nMultiplicative rating is bounded between ±20%\nPortfolio effect of dynamic pricing (assuming constant behaviour) is 0\nSome alternative constraint sets which we may wish to consider (to facilitate other products) are:\nDiscount only\nMultiplicative rating is bounded between 0 and -10%\nPortfolio effect of dynamic pricing (assuming constant behaviour) is 0\nNeutral zone\nMultiplicative rating is bounded between ±20%\nScores within ±5 points of the neutral score should have no adjustment\nPortfolio effect of dynamic pricing (assuming constant behaviour) is 0\nTo fit a price → rating curve for any of these constraints, one has to simply take the historic scores and base premiums and find the parameters which satisfy them. The historic score and\nbase premium dataset\n5. Appendices\nAppendix A. Algorithms\nAppendix B: Pilot\nAppendix C: Assets\nAppendix D: RiskOS Integration\nAppendix E: User Experience Impact\nAppendix F: Onboarding Impact\nAppendix G: BenScoPe vs. Status Quo Head-to-Head\nAppendix H: Scoring and Pricing Customer Impact Analysis\nBenScoPe: How is My Premium Calculated? (PHYD)\nBenScoPe: How is My Premium Calculated? (Annual Plus)', 'content_type': 'text', 'score': 0.023689471, 'meta': {'_split_id': 4}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e0ab4244-e71f-113c-cfe1-94fb0fd52e52'}>, <Document: {'content': 'Absolute Driver Scoring (BenScoPe)\nThis Confluence page documents a proposal known as BenScoPe, which seeks to reform our benchmarking, scoring and pricing that underpins our two current Rideshur products.\nWe describe a scoring structure which can be used for delivering driver and fleet risk scores which are comparable and transferable between contexts, and which do not require the\nmaintenance of a benchmark for any given fleet.\nThe changes described here have implications for how our users will interact with the products based upon this new scoring system. These implications are out of scope for the proposal,\nbut are discussed to some degree in the appendix pages.\nContents\n1. Motivation\n2. Scope\na. Problem Statement\nb. Proposal Summary\n3. Benefits and Risks\n4. Proposal\na. Risk/Score/Price structure, incl. base model (UW)\nb. Risk modelling (incl. setting groups)\ni. Windowing\nii. Normalisation\niii. Risk Prediction Aggregation\nc. Scoring\ni. Driver Score\nii. Fleet Score\nd. Pricing\ni. Determining rating multipliers from score\nii. Alternative Pricing Tables\n5. Appendices\na. Algorithms\nb. Pilot\nc. Assets\nd. RiskOS Integration\ne. User Experience Impact\nf. Onboarding Impact\ng. BenScoPe vs. Status Quo Head-to-Head\n1. Motivation\nOur current scoring system is not delivering for customers or for Humn. For customers, the score is not providing a good enough risk measurement or a fair pricing response. For Humn,\nthe operational costs around onboarding are unsustainable and also impact our customers.\nAn enumeration of the main issues follows.\n1. Our scores are not absolute, only relative.\na. Most fleet scores hover uninspiringly around 50\nb. We can’t compare fleets to each other\nc. We can’t compare drivers from different fleets\n2. Our benchmarking process is flawed and slow\na. It delays onboarding\nb. The behaviour we observe during benchmarking may not be representative\nc. It creates a lot of day-to-day operational work, especially for the Data Science team, who make the benchmarking measurement\n3. Our risk modelling is complex, retrospective and inefficient\na. Making risk predictions at the trip level is volatile, and mitigation of this has introduced complexity\nb. Interventions can only be made at the driver level, so the focus on single trips is an error\nc. There is no need to make online predictions in order to do online pricing\n2. Scope\nThe Rideshur dynamic scoring and pricing system is the scope of this proposal.\n2.a Problem Statement\nThe system we are considering changing here aims to meet two goals\x0c1. Accurately measure risk\n2. Help customers reduce risk\n3. Collect the right amount of money to hit a given loss ratio target\nThe problem statement is therefore:\n2.b Proposal Summary\n1. No more benchmarking\n2. Risk modelling and scores made at driver level, published daily\n3. Fleet score is the average of driver scores, weighted by mileage, published daily\n4. Scores are absolute and do not depend on fleet\n5. Use a score → rating map to transform a score into a discount/loading. This can be universal or fleet specific\n6. ', 'content_type': 'text', 'score': 0.01572399, 'meta': {'_split_id': 0}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '1d43e2e3-6114-32c7-d82f-8598abce23f6'}>, <Document: {'content': 'Use setting groups to normalise risk model outputs across different settings such as driving in vans vs driving in cars\n3. Benefits and Risks\nThe proposal aims to deliver the following benefits\nWe have identified the following risks\n4. Proposal\n4.a Base Model and Dynamic Model\nWe do not propose to change the relationship between the base model (owned by Underwriting) and the dynamic model (owned by Data Science).\nBase model provides a base price for a given fleet\nDynamic model provides a multiplicative adjustment to the base price, within the bounds of ±20%\n4.b Risk modelling\nThere are two main changes proposed here. The first is to use a window of past driver behaviour to make a risk estimate about the driver’s future behaviour. This is a deviation from our\ncurrent method of making risk estimates retrospectively at the trip level. The volatility of making retrospective estimates of risk at trip-level is illustrated here, which plots the trip scores for\na single driver over a week-long period.\nThe second change is to introduce a normalisation layer to the output of our models so that the risk estimate is given in relation to the average risk estimated over historic data.\nGiven some telematics data for a set of customers, provide:\nA score which accurately represents the risk in a way understandable and actionable for customers\nA corresponding pricing adjustment which is fair, cost-neutral and promotes improvements in behaviour with respect to risk.\nRemove the uncertainty and operational cost of benchmarking\nScores become more interpretable and have meaning in multiple contexts\nTrips no longer need to be scored individually, so we have the option to decrease load on our scoring pipeline by using batch computations instead\nA flexible framework for converting scores into prices that can accommodate more complexity as our datasets grow\nWe may collect less than the quoted premium for fleets who are less risky. This is because the system will respond more directly to behavioural change\nThere is no guarantee that a fleet will start their policy with a neutral score or rating (as is currently the case). This has the potential for a bad user experience in some cases so\nwe must try and handle this issue\nWe will no longer calculate risk estimates at the trip level and instead focus on making driver-level risk predictions about the future.\x0c4.b.i Driver Settings\nWe introduce the concept of driver settings, which are arbitrary groupings allowing us to control for different contexts in which the risk models may respond differently. For example, two\nsettings in which we might observe a driver are van and car . We propose to handle the behaviour in each setting separately, aggregating it up to the driver level after a normalisation\nstep.\nNote that driver settings can be used for more complex groupings in future if we wish, controlling for aspects other than vehicle type, such as business type.\n', 'content_type': 'text', 'score': 0.0062655336, 'meta': {'_split_id': 1}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '5ac6e8ee-98b1-7f4e-ea4f-4cf184155fea'}>], 'root_node': 'Query', 'params': {'Retriever': {'top_k': 5}}, 'query': 'How would Revolut be impacted by AIG going bankrupt?', 'node_id': 'PromptNode'}
Prompt:  <haystack.nodes.prompt.prompt_node.PromptNode object at 0x7fa128c75410>
Ranker:  <haystack.nodes.ranker.lost_in_the_middle.LostInTheMiddleRanker object at 0x7fa128de40d0>
Answer:  {'answers': [<Answer {'answer': 'The documents do not provide information on the CEO of Revolut.', 'type': 'generative', 'score': None, 'context': None, 'offsets_in_document': None, 'offsets_in_context': None, 'document_ids': ['18fb30a73ba020d099c5fbb7d9701283', 'b738c2ab97903c4010c85a004ac4e747', '879c75b6c3eb46820d3ab80d48182167', 'cd34d7abce9d16c9d3edb066d58a7304'], 'meta': {'prompt': "Given the provided Documents, answer the Query.\n\n                                                Query: Write a brief introduction of Revolut's CEO\n\n                                                Documents: Access exclusive data for free\nTotal amount raised across all funding rounds\nTotal number of Crunchbase contacts associated with this organization\nTotal number of employee profiles an organization has on Crunchbase\nTotal number of investment firms and individual investors\nTotal number of organizations similar to the given organization\n⚡Premium Feature\nThis profile is locked. If you'd like to suggest changes to this profile, please email us at support@crunchbase.com\nDescriptive keyword for an Organization (e.g. SaaS, Android, Cloud Computing, Medical Device)\nWhere the organization is headquartered (e.g. San Francisco Bay Area, Silicon Valley)\nDate the Organization was founded\nFounders of the organization\nOperating Status of Organization e.g. Active, Closed\nLast funding round type (e.g. Seed, Series A, Private Equity)\nThe legal name of the organization\nTags are labels assigned to organizations, which identify their belonging to a group with that shared label\nWhether an Organization is for profit or non-profit\nOrganization's general phone number Terms of Service | Privacy Policy | Sitemap | © 2023 Crunchbase Inc. All Rights Reserved. (0.1.15009 715)\nCookie Settings\nDo Not Sell or Share My Personal Info\nThis profile is locked. If you'd like to suggest changes to this profile, please email us at support@crunchbase.com Terms of Service | Privacy Policy | Sitemap | © 2023 Crunchbase Inc. All Rights Reserved. (0.1.15009 715)\nCookie Settings\nDo Not Sell or Share My Personal Info\nNumber of news articles that reference the Person Terms of Service | Privacy Policy | Sitemap | © 2023 Crunchbase Inc. All Rights Reserved. (0.1.15009 715)\nCookie Settings\nDo Not Sell or Share My Personal Info\nNumber of Organizations that the person founded\nAlgorithmic rank assigned to the top 100,000 most active People\nThe person's primary job title\nThe organization associated to the person's primary job\nWhere the person is located (e.g. Europe, Menlo Park, China)\nWhere the person is located (e.g. San Francisco Bay Area, Silicon Valley)\nA Person's gender\nAlternate or previous names for the individual\nLink to a Person's LinkedIn page\nLink to a Person's Twitter page\nTotal number of current Jobs the person has\nTotal number of past Jobs the person has\nOrganization Name: This is the name of the organization\nTitle At Company: Title of a Person's Job\nStart Date: Start date of the Person's Job\nEnd Date: End date of the Person's Job\nHub Name: Name of the Hub\nCB Rank (Hub): Algorithmic rank assigned to the top 100,000 most active Hubs\nTotal number of events the individual appeared in\nNumber of news articles that reference the Person\n                                                Answer: \n                                            "}}>], 'invocation_context': {'query': "Write a brief introduction of Revolut's CEO", 'documents': [<Document: {'content': "Access exclusive data for free\nTotal amount raised across all funding rounds\nTotal number of Crunchbase contacts associated with this organization\nTotal number of employee profiles an organization has on Crunchbase\nTotal number of investment firms and individual investors\nTotal number of organizations similar to the given organization\n⚡Premium Feature\nThis profile is locked. If you'd like to suggest changes to this profile, please email us at support@crunchbase.com\nDescriptive keyword for an Organization (e.g. SaaS, Android, Cloud Computing, Medical Device)\nWhere the organization is headquartered (e.g. San Francisco Bay Area, Silicon Valley)\nDate the Organization was founded\nFounders of the organization\nOperating Status of Organization e.g. Active, Closed\nLast funding round type (e.g. Seed, Series A, Private Equity)\nThe legal name of the organization\nTags are labels assigned to organizations, which identify their belonging to a group with that shared label\nWhether an Organization is for profit or non-profit\nOrganization's general phone number", 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.crunchbase.com/organization/revolut', 'timestamp': 1701191208, 'search.score': 0.14545454545454545, 'search.position': 3, 'snippet_text': 'Revolut is a financial services company that specializes in mobile banking, card payments, money remittance, and foreign exchange.', '_split_id': 0, 'score': '0.21739233'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '18fb30a73ba020d099c5fbb7d9701283'}>, <Document: {'content': "Terms of Service | Privacy Policy | Sitemap | © 2023 Crunchbase Inc. All Rights Reserved. (0.1.15009 715)\nCookie Settings\nDo Not Sell or Share My Personal Info\nThis profile is locked. If you'd like to suggest changes to this profile, please email us at support@crunchbase.com", 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.crunchbase.com/organization/revolut/company_overview/overview_timeline', 'timestamp': 1701191208, 'search.score': 0.12727272727272726, 'search.position': 4, 'snippet_text': 'Revolut is a financial services company that specializes in mobile banking, card payments, money remittance, and foreign exchange.', '_split_id': 0, 'score': '0.1973416'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b738c2ab97903c4010c85a004ac4e747'}>, <Document: {'content': 'Terms of Service | Privacy Policy | Sitemap | © 2023 Crunchbase Inc. All Rights Reserved. (0.1.15009 715)\nCookie Settings\nDo Not Sell or Share My Personal Info\nNumber of news articles that reference the Person', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.crunchbase.com/person/nikolay-storonsky/person_overview_default/timeline', 'timestamp': 1701191208, 'search.score': 0.16363636363636364, 'search.position': 2, 'snippet_text': 'Nikolay Storonsky is the Founder and CEO at Revolut. He is a former Equity Derivatives Trader at Credit Suisse and Lehman Brothers. Storons...', '_split_id': 0, 'score': '0.19374847'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '879c75b6c3eb46820d3ab80d48182167'}>, <Document: {'content': "Terms of Service | Privacy Policy | Sitemap | © 2023 Crunchbase Inc. All Rights Reserved. (0.1.15009 715)\nCookie Settings\nDo Not Sell or Share My Personal Info\nNumber of Organizations that the person founded\nAlgorithmic rank assigned to the top 100,000 most active People\nThe person's primary job title\nThe organization associated to the person's primary job\nWhere the person is located (e.g. Europe, Menlo Park, China)\nWhere the person is located (e.g. San Francisco Bay Area, Silicon Valley)\nA Person's gender\nAlternate or previous names for the individual\nLink to a Person's LinkedIn page\nLink to a Person's Twitter page\nTotal number of current Jobs the person has\nTotal number of past Jobs the person has\nOrganization Name: This is the name of the organization\nTitle At Company: Title of a Person's Job\nStart Date: Start date of the Person's Job\nEnd Date: End date of the Person's Job\nHub Name: Name of the Hub\nCB Rank (Hub): Algorithmic rank assigned to the top 100,000 most active Hubs\nTotal number of events the individual appeared in\nNumber of news articles that reference the Person", 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.crunchbase.com/person/nikolay-storonsky', 'timestamp': 1701191208, 'search.score': 0.18181818181818182, 'search.position': 1, 'snippet_text': 'Overview. Nikolay Storonsky is the Founder and CEO at Revolut. He is a former Equity Derivatives Trader at Credit Suisse and Lehman Brothers. Economic School.', '_split_id': 0, 'score': '0.19894303'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'cd34d7abce9d16c9d3edb066d58a7304'}>], 'answers': [<Answer {'answer': 'The documents do not provide information on the CEO of Revolut.', 'type': 'generative', 'score': None, 'context': None, 'offsets_in_document': None, 'offsets_in_context': None, 'document_ids': ['18fb30a73ba020d099c5fbb7d9701283', 'b738c2ab97903c4010c85a004ac4e747', '879c75b6c3eb46820d3ab80d48182167', 'cd34d7abce9d16c9d3edb066d58a7304'], 'meta': {'prompt': "Given the provided Documents, answer the Query.\n\n                                                Query: Write a brief introduction of Revolut's CEO\n\n                                                Documents: Access exclusive data for free\nTotal amount raised across all funding rounds\nTotal number of Crunchbase contacts associated with this organization\nTotal number of employee profiles an organization has on Crunchbase\nTotal number of investment firms and individual investors\nTotal number of organizations similar to the given organization\n⚡Premium Feature\nThis profile is locked. If you'd like to suggest changes to this profile, please email us at support@crunchbase.com\nDescriptive keyword for an Organization (e.g. SaaS, Android, Cloud Computing, Medical Device)\nWhere the organization is headquartered (e.g. San Francisco Bay Area, Silicon Valley)\nDate the Organization was founded\nFounders of the organization\nOperating Status of Organization e.g. Active, Closed\nLast funding round type (e.g. Seed, Series A, Private Equity)\nThe legal name of the organization\nTags are labels assigned to organizations, which identify their belonging to a group with that shared label\nWhether an Organization is for profit or non-profit\nOrganization's general phone number Terms of Service | Privacy Policy | Sitemap | © 2023 Crunchbase Inc. All Rights Reserved. (0.1.15009 715)\nCookie Settings\nDo Not Sell or Share My Personal Info\nThis profile is locked. If you'd like to suggest changes to this profile, please email us at support@crunchbase.com Terms of Service | Privacy Policy | Sitemap | © 2023 Crunchbase Inc. All Rights Reserved. (0.1.15009 715)\nCookie Settings\nDo Not Sell or Share My Personal Info\nNumber of news articles that reference the Person Terms of Service | Privacy Policy | Sitemap | © 2023 Crunchbase Inc. All Rights Reserved. (0.1.15009 715)\nCookie Settings\nDo Not Sell or Share My Personal Info\nNumber of Organizations that the person founded\nAlgorithmic rank assigned to the top 100,000 most active People\nThe person's primary job title\nThe organization associated to the person's primary job\nWhere the person is located (e.g. Europe, Menlo Park, China)\nWhere the person is located (e.g. San Francisco Bay Area, Silicon Valley)\nA Person's gender\nAlternate or previous names for the individual\nLink to a Person's LinkedIn page\nLink to a Person's Twitter page\nTotal number of current Jobs the person has\nTotal number of past Jobs the person has\nOrganization Name: This is the name of the organization\nTitle At Company: Title of a Person's Job\nStart Date: Start date of the Person's Job\nEnd Date: End date of the Person's Job\nHub Name: Name of the Hub\nCB Rank (Hub): Algorithmic rank assigned to the top 100,000 most active Hubs\nTotal number of events the individual appeared in\nNumber of news articles that reference the Person\n                                                Answer: \n                                            "}}>], 'prompts': ["Given the provided Documents, answer the Query.\n\n                                                Query: Write a brief introduction of Revolut's CEO\n\n                                                Documents: Access exclusive data for free\nTotal amount raised across all funding rounds\nTotal number of Crunchbase contacts associated with this organization\nTotal number of employee profiles an organization has on Crunchbase\nTotal number of investment firms and individual investors\nTotal number of organizations similar to the given organization\n⚡Premium Feature\nThis profile is locked. If you'd like to suggest changes to this profile, please email us at support@crunchbase.com\nDescriptive keyword for an Organization (e.g. SaaS, Android, Cloud Computing, Medical Device)\nWhere the organization is headquartered (e.g. San Francisco Bay Area, Silicon Valley)\nDate the Organization was founded\nFounders of the organization\nOperating Status of Organization e.g. Active, Closed\nLast funding round type (e.g. Seed, Series A, Private Equity)\nThe legal name of the organization\nTags are labels assigned to organizations, which identify their belonging to a group with that shared label\nWhether an Organization is for profit or non-profit\nOrganization's general phone number Terms of Service | Privacy Policy | Sitemap | © 2023 Crunchbase Inc. All Rights Reserved. (0.1.15009 715)\nCookie Settings\nDo Not Sell or Share My Personal Info\nThis profile is locked. If you'd like to suggest changes to this profile, please email us at support@crunchbase.com Terms of Service | Privacy Policy | Sitemap | © 2023 Crunchbase Inc. All Rights Reserved. (0.1.15009 715)\nCookie Settings\nDo Not Sell or Share My Personal Info\nNumber of news articles that reference the Person Terms of Service | Privacy Policy | Sitemap | © 2023 Crunchbase Inc. All Rights Reserved. (0.1.15009 715)\nCookie Settings\nDo Not Sell or Share My Personal Info\nNumber of Organizations that the person founded\nAlgorithmic rank assigned to the top 100,000 most active People\nThe person's primary job title\nThe organization associated to the person's primary job\nWhere the person is located (e.g. Europe, Menlo Park, China)\nWhere the person is located (e.g. San Francisco Bay Area, Silicon Valley)\nA Person's gender\nAlternate or previous names for the individual\nLink to a Person's LinkedIn page\nLink to a Person's Twitter page\nTotal number of current Jobs the person has\nTotal number of past Jobs the person has\nOrganization Name: This is the name of the organization\nTitle At Company: Title of a Person's Job\nStart Date: Start date of the Person's Job\nEnd Date: End date of the Person's Job\nHub Name: Name of the Hub\nCB Rank (Hub): Algorithmic rank assigned to the top 100,000 most active Hubs\nTotal number of events the individual appeared in\nNumber of news articles that reference the Person\n                                                Answer: \n                                            "]}, 'documents': [<Document: {'content': "Access exclusive data for free\nTotal amount raised across all funding rounds\nTotal number of Crunchbase contacts associated with this organization\nTotal number of employee profiles an organization has on Crunchbase\nTotal number of investment firms and individual investors\nTotal number of organizations similar to the given organization\n⚡Premium Feature\nThis profile is locked. If you'd like to suggest changes to this profile, please email us at support@crunchbase.com\nDescriptive keyword for an Organization (e.g. SaaS, Android, Cloud Computing, Medical Device)\nWhere the organization is headquartered (e.g. San Francisco Bay Area, Silicon Valley)\nDate the Organization was founded\nFounders of the organization\nOperating Status of Organization e.g. Active, Closed\nLast funding round type (e.g. Seed, Series A, Private Equity)\nThe legal name of the organization\nTags are labels assigned to organizations, which identify their belonging to a group with that shared label\nWhether an Organization is for profit or non-profit\nOrganization's general phone number", 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.crunchbase.com/organization/revolut', 'timestamp': 1701191208, 'search.score': 0.14545454545454545, 'search.position': 3, 'snippet_text': 'Revolut is a financial services company that specializes in mobile banking, card payments, money remittance, and foreign exchange.', '_split_id': 0, 'score': '0.21739233'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '18fb30a73ba020d099c5fbb7d9701283'}>, <Document: {'content': "Terms of Service | Privacy Policy | Sitemap | © 2023 Crunchbase Inc. All Rights Reserved. (0.1.15009 715)\nCookie Settings\nDo Not Sell or Share My Personal Info\nThis profile is locked. If you'd like to suggest changes to this profile, please email us at support@crunchbase.com", 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.crunchbase.com/organization/revolut/company_overview/overview_timeline', 'timestamp': 1701191208, 'search.score': 0.12727272727272726, 'search.position': 4, 'snippet_text': 'Revolut is a financial services company that specializes in mobile banking, card payments, money remittance, and foreign exchange.', '_split_id': 0, 'score': '0.1973416'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'b738c2ab97903c4010c85a004ac4e747'}>, <Document: {'content': 'Terms of Service | Privacy Policy | Sitemap | © 2023 Crunchbase Inc. All Rights Reserved. (0.1.15009 715)\nCookie Settings\nDo Not Sell or Share My Personal Info\nNumber of news articles that reference the Person', 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.crunchbase.com/person/nikolay-storonsky/person_overview_default/timeline', 'timestamp': 1701191208, 'search.score': 0.16363636363636364, 'search.position': 2, 'snippet_text': 'Nikolay Storonsky is the Founder and CEO at Revolut. He is a former Equity Derivatives Trader at Credit Suisse and Lehman Brothers. Storons...', '_split_id': 0, 'score': '0.19374847'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '879c75b6c3eb46820d3ab80d48182167'}>, <Document: {'content': "Terms of Service | Privacy Policy | Sitemap | © 2023 Crunchbase Inc. All Rights Reserved. (0.1.15009 715)\nCookie Settings\nDo Not Sell or Share My Personal Info\nNumber of Organizations that the person founded\nAlgorithmic rank assigned to the top 100,000 most active People\nThe person's primary job title\nThe organization associated to the person's primary job\nWhere the person is located (e.g. Europe, Menlo Park, China)\nWhere the person is located (e.g. San Francisco Bay Area, Silicon Valley)\nA Person's gender\nAlternate or previous names for the individual\nLink to a Person's LinkedIn page\nLink to a Person's Twitter page\nTotal number of current Jobs the person has\nTotal number of past Jobs the person has\nOrganization Name: This is the name of the organization\nTitle At Company: Title of a Person's Job\nStart Date: Start date of the Person's Job\nEnd Date: End date of the Person's Job\nHub Name: Name of the Hub\nCB Rank (Hub): Algorithmic rank assigned to the top 100,000 most active Hubs\nTotal number of events the individual appeared in\nNumber of news articles that reference the Person", 'content_type': 'text', 'score': None, 'meta': {'url': 'https://www.crunchbase.com/person/nikolay-storonsky', 'timestamp': 1701191208, 'search.score': 0.18181818181818182, 'search.position': 1, 'snippet_text': 'Overview. Nikolay Storonsky is the Founder and CEO at Revolut. He is a former Equity Derivatives Trader at Credit Suisse and Lehman Brothers. Economic School.', '_split_id': 0, 'score': '0.19894303'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'cd34d7abce9d16c9d3edb066d58a7304'}>], 'root_node': 'Query', 'params': {}, 'query': "Write a brief introduction of Revolut's CEO", 'node_id': 'PromptNode'}